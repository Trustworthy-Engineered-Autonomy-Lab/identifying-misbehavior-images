{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1baceedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 13:40:56.893448: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-05 13:40:57.585165: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def clear_memory():\n",
    "    K.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6171d505",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     13\u001b[0m image_extensions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.gif\u001b[39m\u001b[38;5;124m\"\u001b[39m} \n\u001b[1;32m     14\u001b[0m images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     15\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, f)\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(f)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m image_extensions\n\u001b[1;32m     18\u001b[0m ]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Directories containing the datasets\u001b[39;00m\n\u001b[1;32m     22\u001b[0m normal_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/UFAD/mohitkukreja/Documents/data_perfect_driving/images/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'folder' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Lambda, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Directories containing the datasets\n",
    "normal_dir = '/home/UFAD/mohitkukreja/Documents/data_perfect_driving/images/'\n",
    "blurry_dir = '/home/UFAD/mohitkukreja/Documents/data_perfect_driving/images_blurred/'\n",
    "dirt_dir = '/home/UFAD/mohitkukreja/Documents/data_perfect_driving/images_dirt/'\n",
    "tape_dir = '/home/UFAD/mohitkukreja/Documents/data_perfect_driving/images_tape/'\n",
    "directories = [normal_dir, blurry_dir, dirt_dir, tape_dir]\n",
    "\n",
    "# Parameters\n",
    "image_size = (128, 128)  # Resize all images to 128x128\n",
    "batch_size = 64  # Adjust as per your system's capacity\n",
    "latent_dim = 16  # Latent space dimension\n",
    "epochs = 20\n",
    "\n",
    "# Data loading function\n",
    "def load_images_from_directories(directories, image_size):\n",
    "    \"\"\"\n",
    "    Load and preprocess images from multiple directories.\n",
    "    \"\"\"\n",
    "    all_images = []\n",
    "    \n",
    "    for directory in directories:\n",
    "        for filename in os.listdir(directory):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                # Load image\n",
    "                img = load_img(filepath, target_size=image_size)\n",
    "                # Convert to numpy array\n",
    "                img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "                all_images.append(img_array)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {filepath}: {e}\")\n",
    "    \n",
    "    return np.array(all_images)\n",
    "\n",
    "# Load and preprocess the data\n",
    "data = load_images_from_directories(directories, image_size)\n",
    "print(f\"Total images loaded: {data.shape[0]}\")\n",
    "\n",
    "# Shuffle data\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Split into train and validation sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(data) * split_ratio)\n",
    "x_train = data[:split_index]\n",
    "x_val = data[split_index:]\n",
    "\n",
    "print(f\"Training set size: {x_train.shape[0]}, Validation set size: {x_val.shape[0]}\")\n",
    "\n",
    "# VAE Model definition\n",
    "# Encoder\n",
    "input_img = Input(shape=(128, 128, 3))\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "# Sampling function\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# Decoder\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "x = Dense(16 * 16 * 64, activation='relu')(decoder_input)\n",
    "x = Reshape((16, 16, 64))(x)\n",
    "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "decoded_img = Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Define encoder and decoder models\n",
    "encoder = Model(input_img, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "decoder = Model(decoder_input, decoded_img, name=\"decoder\")\n",
    "\n",
    "# Connect encoder and decoder into a VAE model\n",
    "output_img = decoder(encoder(input_img)[2])\n",
    "vae = Model(input_img, output_img, name=\"vae\")\n",
    "\n",
    "# VAE Loss\n",
    "reconstruction_loss = MeanSquaredError()(K.flatten(input_img), K.flatten(output_img))\n",
    "kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "# Train the VAE\n",
    "history = vae.fit(x_train, x_train, \n",
    "                  epochs=epochs, \n",
    "                  batch_size=batch_size, \n",
    "                  validation_data=(x_val, x_val))\n",
    "\n",
    "# Evaluate the VAE\n",
    "def plot_reconstructions(vae, images, n=10):\n",
    "    \"\"\"\n",
    "    Plot original and reconstructed images.\n",
    "    \"\"\"\n",
    "    reconstructed = vae.predict(images[:n])\n",
    "    fig, axes = plt.subplots(2, n, figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # Original\n",
    "        axes[0, i].imshow(images[i])\n",
    "        axes[0, i].axis('off')\n",
    "        # Reconstructed\n",
    "        axes[1, i].imshow(reconstructed[i])\n",
    "        axes[1, i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize reconstructions\n",
    "plot_reconstructions(vae, x_val)\n",
    "\n",
    "# Anomaly detection\n",
    "def compute_anomaly_score(vae, images):\n",
    "    \"\"\"\n",
    "    Compute anomaly scores as reconstruction loss for given images.\n",
    "    \"\"\"\n",
    "    reconstructed = vae.predict(images)\n",
    "    return np.mean(np.square(images - reconstructed), axis=(1, 2, 3))\n",
    "\n",
    "anomaly_scores = compute_anomaly_score(vae, x_val)\n",
    "threshold = np.percentile(anomaly_scores, 95)  # Set threshold at 95th percentile\n",
    "anomalies = x_val[anomaly_scores > threshold]\n",
    "\n",
    "print(f\"Number of anomalies detected: {len(anomalies)}\")\n",
    "\n",
    "# Visualize anomalies\n",
    "plot_reconstructions(vae, anomalies, n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d705767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
